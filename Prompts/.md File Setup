# Setting Up Your Initial .MD Files for Agentic Systems

This repository provides a framework for setting up Markdown-based files and folders to build self-improving agentic systems powered by any LLM (e.g., Claude, GPT, etc.). It uses a PARA structure (Projects, Areas, Resources, Archives) for organization, with Markdown for persistence and Python for orchestration.

## Quick Start
1. **Generate the Repo**: Copy the super prompt below into your chosen LLM (e.g., Claude, Grok) and run it. Replace "(insert LLM here)" with your LLM (e.g., "Claude").
2. **Output**: The LLM will generate file contents in a .zip-ready format. Save them to a folder named `(InsertLLMHere)AgentsVault/`.
3. **Setup**:
   - Install dependencies: `make install` (uses pyproject.toml).
   - Version control: Initialize Git and commit.
   - Tools: Open in Obsidian for linking/visualization; use VS Code for Python.
   - Run: `make run` to start the agent runner.
4. **Customization**: Upload skills to `skills/` using the template in `SKILLS_INDEX.md`. Update config in `src/config.py`.

## Super Prompt
{
You are an AI assistant tasked with generating a complete, production-ready repository for building and using self-improving agents powered by an LLM (e.g., via its API, SDK, or related frameworks). This is for my personal knowledge management (PKM) system using Markdown files for consistency, updates, and version control (e.g., via Git and tools like Obsidian). I emphasize modularity, bi-directional linking, code snippets, automation for updates (e.g., scripts or agents to summarize/tag), and self-improving capabilities.

Draw from the 9 learning loops concept for self-improving AI agents, which promotes simple, flat Markdown files for persistence, learning, and orchestration as a "stopgap" until AI advances. Key loops: Regression Tracking (REGRESSIONS.md), Prediction Logging, Nightly Extraction, Friction Detection (FRICTIONS.md), Failure-to-Guardrail Pipeline (GUARDRAILS.md), Trust Scoring in Memory, Hypothesis Testing, Self-Review, Knowledge Distillation. Use lightweight .md files that agents can read/write for memory and evolution.

Incorporate best practices from research on Markdown in AI agent systems:
- AGENTS.md as "README for agents": Include project structure, commands (e.g., build/test), conventions (e.g., "Use the LLM for critical tasks"), dos/don'ts (e.g., "Avoid exceeding context limits; checkpoint to files"), concrete examples pointing to real files/patterns, legacy warnings. Keep concise, human-readable, version-controlled. Reduces agent runtime via context engineering.
- File-Based Memory: Use .md for working memory (e.g., TASK_PLAN.md for goals/progress, NOTES.md for research, MEMORY.md for trust-scored entries). Agents read/decide/act/update in cycles. Markdown's strengths: LLM-trained (headers/bullets convey structure), no overhead/schema, human-readable. Add structured sidecars (e.g., JSONL or SQLite) for scalability; hybrid with vector stores if needed, but start simple.
- Optimized Structure: Flat where possible; use PARA folders (Projects, Areas, Resources, Archives). Consistent format: Headings, lists, code blocks, YAML frontmatter for entries (e.g., date, description, resolution). Bi-directional links ([[file.md]]). LLM-friendly: Structured like XML, few-shot examples. For long contexts: Save conversations as .md, reference fragments semantically.
- Full Repo for Effective Agentic System: Build a complete vault (LLMAgentsVault/) importable to code editors or folders for co-working with agents (e.g., via API/scripts). Include: Core PKM files, loop-specific .md, memory files, src/ for Python code templates (e.g., agent definitions, file I/O), skills/ for modular agent "skills" folder structure and templates (YAML/Markdown; do not generate actual skill content—just placeholders like SKILLS_INDEX.md with template for "skill_name: description, tools" to allow uploading wide range of skills later). Automate: Scripts in src/ for nightly extraction/summarization. Git-ready: .gitignore for locals.

Naming Convention Preamble (Mandatory—Apply to ALL Files):
- Python source files: snake_case.py
- Markdown skill definitions: snake_case.md (in skills/)
- Markdown loop definitions: SCREAMING_CASE.md (in loops/)
- Root-level reference docs: SCREAMING_CASE.md
- Test files: test_<module_name>.py
- Data files: snake_case.jsonl / snake_case.json
Any deviation is a bug.

Config-First Architecture (Mandatory):
Create a Settings class in src/config.py using Pydantic BaseSettings. Every model name, file path, retry count, loop schedule interval, and API endpoint must be a field on Settings. Settings must load from environment variables with .env file fallback. No string literals for file paths or model names outside config.py.
loop_orchestrator.py must expose a LOOP_HANDLERS: dict[str, Callable[[], LoopResult]] — each handler must accept no arguments and return a LoopResult from src/models/loop_result.py.
Callable must be imported from collections.abc; LoopResult from src.models.loop_result. Both must appear in the module's import block.

Error Handling Constraints (Mandatory):
All LLM API calls must be wrapped in a retry decorator with exponential back-off (max 3 retries, base 2s). All file I/O operations must use try/except with typed exceptions and log the error before re-raising. No bare except: clauses—all handlers must specify exception type. Every function must have a return type annotation and a one-line docstring.
All file writes in file_io.py must use atomic write semantics: write to <path>.tmp, then os.replace() to the target.

Memory Schema (Mandatory):
Memory entries must conform to a MemoryEntry Pydantic BaseModel with fields: id (UUID), timestamp (ISO8601), loop_type (str), content (str), tags (list[str]), trust_score (float).
Persist as JSONL (one entry per line) at memory/memory.jsonl. Auto-generate MEMORY.md from the JSONL file, not edited directly. Include src/models/memory.py with methods: append(), query_by_tag(), query_by_date_range(), prune_low_trust().

Loop Result Model (Mandatory):
loop_result.py must expose LoopResult(BaseModel) with fields:
- run_id: UUID
- loop_type: str
- status: Literal['success', 'partial', 'failed', 'skipped']
- output: str
- trust_score: float   # 0.0–1.0
- tokens_used: int
- cost_usd: float
- error_message: str | None
- timestamp: datetime   # default to datetime.now(UTC) at construction
- duration_seconds: float   # default 0.0

Full File Manifest (Mandatory—Include These in Every Generation):
- pyproject.toml with all runtime/dev dependencies (e.g., pydantic, pytest, etc.)
- src/__init__.py (even if empty)
- src/utils/__init__.py (even if empty)
- src/models/__init__.py (even if empty)
- Makefile with targets: install, run, test, lint, nightly-dry-run, sync-check (verify all loops/*.md have handlers in loop_orchestrator.py)
- tests/ directory with at least one test file per src/ module (e.g., test_agent_runner.py)
- tests/conftest.py with a mock_llm_client pytest fixture that returns a MagicMock where .messages.create.return_value = MagicMock(content=[MagicMock(text="mock response")], usage=MagicMock(input_tokens=10, output_tokens=20))
- .pre-commit-config.yaml with black, ruff, mypy, and trailing-whitespace hooks
- CHANGELOG.md initialized with v0.1.0 entry
- CONTRIBUTING.md with naming conventions and branch strategy
- .gitignore (include .env, logs/, etc.)
- .env.example (for secrets like API keys)
- SECURITY.md with key rotation procedure and responsible disclosure policy
- AGENTS.md at root — project structure, key commands, dos/don'ts, and a pointer to CONTRIBUTING.md and the loops/ folder.
- src/utils/ with logging_config.py (structured logging), retry.py, validators.py (schema validation)
- src/models/ with memory.py, skill.py, loop_result.py (Pydantic models)
- logs/ (git-ignored runtime logs)
- .github/workflows/ with nightly.yml and ci.yml (PR gate on every pull request: lint, type check, tests on Python 3.11 and 3.12)
- .github/dependabot.yml to auto-update Python and GitHub Actions dependencies weekly
- For loops/: Add YAML front-matter to each defining: loop_id, trigger (schedule/event), timeout_seconds, max_cost_usd, output_schema
- For skills/: Include SKILLS_INDEX.md with YAML template for skills; no actual skill content—empty snake_case.md placeholders if needed for structure
- For memory/: Markdown files + .jsonl sidecars; atomic writes in file_io.py (write to .tmp, then rename)
- README.md at root with: project description, quick-start (3 commands), folder structure table, and a link to CONTRIBUTING.md

Additional Requirements (Mandatory):
- nightly_extraction.py must accept a --dry-run CLI flag that logs all planned actions without making API calls or writing files.
- Add a CI step in ci.yml that warns (not fails) if any root-level .md file has not been modified in the last 60 days.
- output_schema must be a flat YAML dict of field_name: type pairs, e.g. summary: string, trust_delta: float, entries_added: int.

Task: Generate the full repo as a .zip-file-ready output. Go file by file: For each, provide path (e.g., root/Index.md), full content, and a brief optimization note (e.g., "Optimized with error handling: Added retries and typed exceptions"). Structure:
- Start with folder overview (e.g., tree view).
- Then, file by file in logical order (core, loops, memory, src, skills, tests, etc.).
- Use Markdown features: Headings, YAML, code blocks, links.
- End with usage: "Save contents to files, zip as LLMAgentsVault.zip; import to Obsidian/Git; run agents via SDK."

Post-Generation Validation (Mandatory—Perform After Generating All Files):
1. Every .md file in loops/ must have a corresponding Python function in loop_orchestrator.py.
2. Every .md file in skills/ must have a corresponding entry in skills/SKILLS_INDEX.md.
3. Every environment variable referenced in any Python file must be listed in .env.example.
4. Every external Python library imported must be listed in pyproject.toml.
List any inconsistencies found and resolve them before finalizing the output.
}

## Best Practices
- Use Git for versioning .md files.
- Automate updates with nightly scripts.
- Scale memory with JSONL sidecars for queries.

For issues, see CONTRIBUTING.md in the generated repo.
